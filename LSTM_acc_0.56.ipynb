{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700e8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29678c",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8097a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3950 entries, 0 to 3949\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   class         3950 non-null   object\n",
      " 1   conversation  3950 non-null   object\n",
      " 2   okt           3950 non-null   object\n",
      " 3   mecab         3950 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 123.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data2.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c616362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'저기요 혹시 날이 너무 뜨겁잖아요 저희 회사에서 이 선크림 파는데 한 번 손등에 발라보실래요 아 진짜요 안 그래도 선크림 필요해서 알아보던 중인데 한 번 발라 볼게요 여기 한 번 발라보세요 진짜 성분도 좋고 다 좋아요 음 성분이 좋다고 하셔서 좋은거 같기는 한데 제 피부에 맞지 않나봐요 피부가 따끔거리네요 이번에 진짜 열심히 연구해서 만든건데 피부가 많이 예민하신가봐요 네 많이 예민해요 그럼 많이 파시고 안녕히 계세요 아니 저기요 돈 안내요 네 발라보는것도 돈 내야 하나요 그럼 이거 누구한테 팔아요 당신이 바른거를 아니 먼저 발라 보시라고 하셨잖아요 먼저 권유해놓고 사라고 강매하는거 갈취인거 몰라요 내가 안 사도 된다고 말 한 적 있어 그것도 모르고 바른걸 누구 탓 하나 빨리 사 당신이 바른거 당신이 사야지 진짜 어이가 없어서 다른 사람들한텐 이렇게 갈취하지마세요 화딱지나네'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conversation'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc2f118",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>conversation</th>\n",
       "      <th>okt</th>\n",
       "      <th>mecab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>지금 너 스스로를 죽여달라고 애원하는 것인가  아닙니다 죄송합니다  죽을 거면 혼자...</td>\n",
       "      <td>['지금', '너', '스스로', '를', '죽여', '달라', '고', '애원',...</td>\n",
       "      <td>['지금', '너', '스스로', '를', '죽여', '달', '라고', '애원',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>협박 대화</td>\n",
       "      <td>길동경찰서입니다 시 분 마트에 폭발물을 설치할거다 네 똑바로 들어 한번만 더 얘기한...</td>\n",
       "      <td>['길동', '경찰서', '입니다', '시', '분', '마트', '에', '폭발물...</td>\n",
       "      <td>['길동', '경찰서', '입니다', '시', '분', '마트', '에', '폭발물...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기타 괴롭힘 대화</td>\n",
       "      <td>너 되게 귀여운거 알지 나보다 작은 남자는 첨봤어 그만해 니들 놀리는거 재미없어 지...</td>\n",
       "      <td>['너', '되게', '귀여운거', '알', '지', '나', '보다', '작은',...</td>\n",
       "      <td>['너', '되게', '귀여운', '거', '알', '지', '나', '보다', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>어이 거기 예 너 말이야 너 이리 오라고 무슨 일 너 옷 좋아보인다 얘 돈 좀 있나...</td>\n",
       "      <td>['어이', '거기', '예', '너', '말', '이야', '너', '이리', '...</td>\n",
       "      <td>['어', '이', '거기', '예', '너', '말', '이', '야', '너',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>갈취 대화</td>\n",
       "      <td>저기요 혹시 날이 너무 뜨겁잖아요 저희 회사에서 이 선크림 파는데 한 번 손등에 발...</td>\n",
       "      <td>['저기', '요', '혹시', '날', '이', '너무', '뜨겁잖아요', '저희...</td>\n",
       "      <td>['저기', '요', '혹시', '날', '이', '너무', '뜨겁', '잖아요',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                       conversation  \\\n",
       "0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가  아닙니다 죄송합니다  죽을 거면 혼자...   \n",
       "1      협박 대화  길동경찰서입니다 시 분 마트에 폭발물을 설치할거다 네 똑바로 들어 한번만 더 얘기한...   \n",
       "2  기타 괴롭힘 대화  너 되게 귀여운거 알지 나보다 작은 남자는 첨봤어 그만해 니들 놀리는거 재미없어 지...   \n",
       "3      갈취 대화  어이 거기 예 너 말이야 너 이리 오라고 무슨 일 너 옷 좋아보인다 얘 돈 좀 있나...   \n",
       "4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요 저희 회사에서 이 선크림 파는데 한 번 손등에 발...   \n",
       "\n",
       "                                                 okt  \\\n",
       "0  ['지금', '너', '스스로', '를', '죽여', '달라', '고', '애원',...   \n",
       "1  ['길동', '경찰서', '입니다', '시', '분', '마트', '에', '폭발물...   \n",
       "2  ['너', '되게', '귀여운거', '알', '지', '나', '보다', '작은',...   \n",
       "3  ['어이', '거기', '예', '너', '말', '이야', '너', '이리', '...   \n",
       "4  ['저기', '요', '혹시', '날', '이', '너무', '뜨겁잖아요', '저희...   \n",
       "\n",
       "                                               mecab  \n",
       "0  ['지금', '너', '스스로', '를', '죽여', '달', '라고', '애원',...  \n",
       "1  ['길동', '경찰서', '입니다', '시', '분', '마트', '에', '폭발물...  \n",
       "2  ['너', '되게', '귀여운', '거', '알', '지', '나', '보다', '...  \n",
       "3  ['어', '이', '거기', '예', '너', '말', '이', '야', '너',...  \n",
       "4  ['저기', '요', '혹시', '날', '이', '너무', '뜨겁', '잖아요',...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54326dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0b2db",
   "metadata": {},
   "source": [
    "### 패딩, 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3fb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 토큰화 및 패딩\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['conversation'])\n",
    "sequences = tokenizer.texts_to_sequences(df['conversation'])\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f27abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    }
   ],
   "source": [
    "# LSTM 모델 구성 함수\n",
    "# LSTM 모델 구성 함수\n",
    "def create_lstm_model(embedding_dim, lstm_units, hidden_units, dropout_rate=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_length))\n",
    "    model.add(LSTM(units=lstm_units, dropout=dropout_rate))\n",
    "    model.add(Dense(hidden_units, activation='relu'))  # 추가된 은닉 레이어\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# KerasClassifier를 활용하여 Keras 모델을 scikit-learn 모델로 래핑\n",
    "model = KerasClassifier(build_fn=create_lstm_model, verbose=0)\n",
    "\n",
    "# 그리드 서치를 통한 모델 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    'embedding_dim': [50, 100],\n",
    "    'lstm_units': [64, 128],\n",
    "    'hidden_units':[64, 128, 256],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델의 하이퍼파라미터 출력\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f481973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 클래스 인덱스를 원-핫 인코딩 형태로 변환\n",
    "y_train_encoded = tf.one_hot(y_train, depth=4)  # 클래스 개수인 4로 depth 설정\n",
    "y_test_encoded = tf.one_hot(y_test, depth=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath='best_model.h5', save_best_only=True),\n",
    "    LearningRateScheduler(lambda epoch: 1e-3 * (0.6 ** epoch))\n",
    "]\n",
    "\n",
    "# 모델 학습\n",
    "best_model = grid_result.best_estimator_\n",
    "best_model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded), callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 평가\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.round(y_pred).flatten()\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 내부 Keras 모델 저장\n",
    "best_model.model.save('best_lstm_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882657ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('./data/test.json').T\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23948fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(test['text'])\n",
    "sequences = tokenizer.texts_to_sequences(test['text'])\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fea2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 저장한 모델 로드\n",
    "loaded_model = load_model('best_lstm_model.h5')\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred_probs = loaded_model.predict(X)\n",
    "\n",
    "# 예측 확률을 클래스 인덱스로 변환\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# 예측된 클래스 출력\n",
    "print(y_pred_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f83575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 디코딩을 위한 역변환\n",
    "decoded_classes = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# 디코딩된 클래스 출력\n",
    "print(decoded_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aeb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['class'] = decoded_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73489",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩된 클래스를 새로운 인코딩 값으로 매핑하는 딕셔너리 생성\n",
    "new_encoding_dict = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "}\n",
    "\n",
    "# 디코딩된 클래스를 새로운 인코딩 값으로 변환\n",
    "new_encoded_classes = [new_encoding_dict[decoded] for decoded in decoded_classes]\n",
    "\n",
    "# 변환된 새로운 인코딩 값 출력\n",
    "print(new_encoded_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['class'] = new_encoded_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75697c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission = test[['class']]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70673150",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('try1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a838a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['class'] = 0\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['class']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b62535",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('try2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Define the create_lstm_model function\n",
    "def create_lstm_model(embedding_dim, lstm_units, hidden_units, dropout_rate=0.4):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=max_length))\n",
    "    model.add(LSTM(units=lstm_units, dropout=dropout_rate))\n",
    "    model.add(Dense(hidden_units, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a model instance\n",
    "model = create_lstm_model(embedding_dim=100, lstm_units=128, hidden_units=128)\n",
    "\n",
    "# Plot the model and save it as an image file\n",
    "plot_model(model, to_file='lstm_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730616a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
